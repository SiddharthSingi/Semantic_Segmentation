{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"9V3RcLzmh43D","colab_type":"code","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":839},"outputId":"faa1db8e-d7ec-4448-ae89-e8d5a35d71d4","executionInfo":{"status":"ok","timestamp":1534085616106,"user_tz":-330,"elapsed":71285,"user":{"displayName":"siddharth singi","photoUrl":"//lh4.googleusercontent.com/-gtydkiSiSeM/AAAAAAAAAAI/AAAAAAAABG0/pxyexJAINso/s50-c-k-no/photo.jpg","userId":"108767219022458767778"}}},"cell_type":"code","source":["from google.colab import files\n","src = list(files.upload().values())[0]\n","\n","import os\n","cwd = os.getcwd()\n","print(cwd)\n","\n","!pip install tqdm\n","!pip install tensorflow-gpu==1.4"],"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-9789cff8-063a-4ce2-835c-1b12ab4a330a\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-9789cff8-063a-4ce2-835c-1b12ab4a330a\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving helper.py to helper (1).py\n","Saving project_tests.py to project_tests (1).py\n","/content\n","Collecting tqdm\n","  Using cached https://files.pythonhosted.org/packages/7d/e6/19dfaff08fcbee7f3453e5b537e65a8364f1945f921a36d08be1e2ff3475/tqdm-4.24.0-py2.py3-none-any.whl\n","Installing collected packages: tqdm\n","Successfully installed tqdm-4.24.0\n","Collecting tensorflow-gpu==1.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/b5/5219622fa7c17197eb1611eaa045270737e1a57eb854ef5359aac7d79cd7/tensorflow_gpu-1.4.0-cp27-cp27mu-manylinux1_x86_64.whl (170.1MB)\n","\u001b[K    100% |████████████████████████████████| 170.1MB 65kB/s \n","\u001b[?25hCollecting tensorflow-tensorboard<0.5.0,>=0.4.0rc1 (from tensorflow-gpu==1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/cd/f3d14d441eb1c5228aaf7e12e8e94895ae73e9af50383e481610b34357bd/tensorflow_tensorboard-0.4.0-py2-none-any.whl (1.7MB)\n","\u001b[K    100% |████████████████████████████████| 1.7MB 3.7MB/s \n","\u001b[?25hRequirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.4) (2.0.0)\n","Requirement already satisfied: enum34>=1.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.4) (1.1.6)\n","Requirement already satisfied: protobuf>=3.3.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.4) (3.6.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.4) (0.31.1)\n","Requirement already satisfied: backports.weakref>=1.0rc1 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.4) (1.0.post1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.4) (1.11.0)\n","Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow-gpu==1.4) (1.14.5)\n","Collecting bleach==1.5.0 (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow-gpu==1.4)\n","  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n","Requirement already satisfied: futures>=3.1.1; python_version < \"3.2\" in /usr/local/lib/python2.7/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow-gpu==1.4) (3.2.0)\n","Collecting html5lib==0.9999999 (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow-gpu==1.4)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n","\u001b[K    100% |████████████████████████████████| 890kB 4.0MB/s \n","\u001b[?25hRequirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python2.7/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow-gpu==1.4) (0.14.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python2.7/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow-gpu==1.4) (2.6.11)\n","Requirement already satisfied: funcsigs>=1; python_version < \"3.3\" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow-gpu==1.4) (1.0.2)\n","Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow-gpu==1.4) (4.2.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python2.7/dist-packages (from protobuf>=3.3.0->tensorflow-gpu==1.4) (39.1.0)\n","Building wheels for collected packages: html5lib\n","  Running setup.py bdist_wheel for html5lib ... \u001b[?25l-\b \bdone\n","\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n","Successfully built html5lib\n","Installing collected packages: html5lib, bleach, tensorflow-tensorboard, tensorflow-gpu\n","  Found existing installation: html5lib 1.0.1\n","    Uninstalling html5lib-1.0.1:\n","      Successfully uninstalled html5lib-1.0.1\n","  Found existing installation: bleach 2.1.3\n","    Uninstalling bleach-2.1.3:\n","      Successfully uninstalled bleach-2.1.3\n","Successfully installed bleach-1.5.0 html5lib-0.9999999 tensorflow-gpu-1.4.0 tensorflow-tensorboard-0.4.0\n"],"name":"stdout"}]},{"metadata":{"id":"vLhRDFoOT_rQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"outputId":"19e30768-3c79-491e-f40d-40a626585ee6","executionInfo":{"status":"ok","timestamp":1534097625428,"user_tz":-330,"elapsed":21430,"user":{"displayName":"siddharth singi","photoUrl":"//lh4.googleusercontent.com/-gtydkiSiSeM/AAAAAAAAAAI/AAAAAAAABG0/pxyexJAINso/s50-c-k-no/photo.jpg","userId":"108767219022458767778"}}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"metadata":{"id":"JKectqxiVayY","colab_type":"code","colab":{}},"cell_type":"code","source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":0,"outputs":[]},{"metadata":{"id":"I2CNp_nuVjEd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":225},"outputId":"2171b6d6-1975-4f07-de7f-b9b8ac5b4418","executionInfo":{"status":"ok","timestamp":1534104189323,"user_tz":-330,"elapsed":2568,"user":{"displayName":"siddharth singi","photoUrl":"//lh4.googleusercontent.com/-gtydkiSiSeM/AAAAAAAAAAI/AAAAAAAABG0/pxyexJAINso/s50-c-k-no/photo.jpg","userId":"108767219022458767778"}}},"cell_type":"code","source":["import os\n","cwd = os.getcwd()\n","print(cwd)\n","\n","#os.chdir('drive/Colab_Notebooks/Semantic_Segmentation')\n","\n","cwd = os.getcwd()\n","print(cwd)\n","os.listdir(os.getcwd())"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/content/drive/Colab_Notebooks/Semantic_Segmentation\n","/content/drive/Colab_Notebooks/Semantic_Segmentation\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['main2.ipynb',\n"," 'models',\n"," 'runs',\n"," 'helper.py',\n"," 'SemanticSegmentation.ipynb',\n"," '__pycache__',\n"," 'data',\n"," 'main_jupyter.ipynb',\n"," 'main.py',\n"," 'project_tests.py']"]},"metadata":{"tags":[]},"execution_count":6}]},{"metadata":{"id":"K909kQ6JDPLR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1008},"outputId":"dd71b410-e0f3-4c27-f14a-6f1e0ef94556","executionInfo":{"status":"ok","timestamp":1534108763633,"user_tz":-330,"elapsed":3143406,"user":{"displayName":"siddharth singi","photoUrl":"//lh4.googleusercontent.com/-gtydkiSiSeM/AAAAAAAAAAI/AAAAAAAABG0/pxyexJAINso/s50-c-k-no/photo.jpg","userId":"108767219022458767778"}}},"cell_type":"code","source":["import os.path\n","import helper\n","import warnings\n","from distutils.version import LooseVersion\n","import project_tests as tests\n","from tqdm import tqdm\n","import tensorflow as tf\n","\n","\n","# Check TensorFlow Version\n","assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n","print('TensorFlow Version: {}'.format(tf.__version__))\n","\n","# Check for a GPU\n","if not tf.test.gpu_device_name():\n","    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n","else:\n","    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n","    \n","\n","def load_vgg(sess, vgg_path):\n","    \"\"\"\n","    Load Pretrained VGG Model into TensorFlow.\n","    :param sess: TensorFlow Session\n","    :param vgg_path: Path to vgg folder, containing \"variables/\" and \"saved_model.pb\"\n","    :return: Tuple of Tensors from VGG model (image_input, keep_prob, layer3_out, layer4_out, layer7_out)\n","    \"\"\"\n","    # TODO: Implement function\n","    #   Use tf.saved_model.loader.load to load the model and weights    \n","    vgg_tag = 'vgg16'\n","    vgg_input_tensor_name = 'image_input:0'\n","    vgg_keep_prob_tensor_name = 'keep_prob:0'\n","    vgg_layer3_out_tensor_name = 'layer3_out:0'\n","    vgg_layer4_out_tensor_name = 'layer4_out:0'\n","    vgg_layer7_out_tensor_name = 'layer7_out:0'\n","    \n","    tf.saved_model.loader.load(sess, [vgg_tag], vgg_path)\n","    graph = tf.get_default_graph()\n","    \n","    image_input = graph.get_tensor_by_name(vgg_input_tensor_name)\n","    \n","    keep_prob = graph.get_tensor_by_name(vgg_keep_prob_tensor_name)\n","    \n","    layer3_out = graph.get_tensor_by_name(vgg_layer3_out_tensor_name)\n","    \n","    layer4_out = graph.get_tensor_by_name(vgg_layer4_out_tensor_name)\n","    \n","    layer7_out = graph.get_tensor_by_name(vgg_layer7_out_tensor_name)\n","    \n","    return image_input, keep_prob, layer3_out, layer4_out, layer7_out\n","\n","tests.test_load_vgg(load_vgg, tf)\n","\n","def layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes):\n","    \"\"\"\n","    Create the layers for a fully convolutional network.  Build skip-layers using the vgg layers.\n","    :param vgg_layer7_out: TF Tensor for VGG Layer 7 output\n","    :param vgg_layer4_out: TF Tensor for VGG Layer 4 output\n","    :param vgg_layer3_out: TF Tensor for VGG Layer 3 output\n","    :param num_classes: Number of classes to classify\n","    :return: The Tensor for the last layer of output\n","    \"\"\"\n","    # TODO: Implement function\n","    vgg_layer3_out = tf.layers.batch_normalization(vgg_layer3_out, name=\"new_vgg_layer3_bn\")\n","    vgg_layer4_out = tf.layers.batch_normalization(vgg_layer4_out, name=\"new_vgg_layer4_bnt\")\n","    vgg_layer7_out = tf.layers.batch_normalization(vgg_layer7_out, name=\"new_vgg_layer7_bn\")\n","    \n","    #1x1 Convolution on layer 7\n","    layer7_1x1 = tf.layers.conv2d(vgg_layer7_out, filters=num_classes, kernel_size=(1, 1), strides=(1, 1),\n","                                          name='new_layer7_1x1_out', activation=tf.nn.relu,\n","                                          kernel_initializer=tf.truncated_normal_initializer(stddev=0.01),\n","                                          kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3))\n","    \n","    #upsampling on layer7_1x1\n","    layer4_upsampled =  tf.layers.conv2d_transpose(layer7_1x1, vgg_layer4_out.get_shape().as_list()[-1], 4, \n","                                             strides= (2, 2), \n","                                             padding= 'same', \n","                                             kernel_initializer= tf.random_normal_initializer(stddev=0.01), \n","                                             kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3),\n","                                             name='layer4_upsampled')\n","    \n","    #batch normalization on upsampled layer\n","    layer4_upsampled_bn = tf.layers.batch_normalization(layer4_upsampled, name=\"layer4_upsampled_bn\")\n","    \n","    #1x1 Convolution on vgg_layer4_out   \n","    vgg_layer4_1x1 = tf.layers.conv2d(vgg_layer4_out, filters=vgg_layer4_out.get_shape().as_list()[-1], kernel_size=(1, 1), strides=(1, 1),\n","                                          name=\"vgg_layer4_1x1\", activation=tf.nn.relu,\n","                                          kernel_initializer=tf.truncated_normal_initializer(stddev=0.01),\n","                                          kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3))\n","    \n","    #batch normalization on vgg layer\n","    vgg_layer4_1x1_bn = tf.layers.batch_normalization(vgg_layer4_1x1, name=\"vgg_layer4_1x1_bn\")\n","    \n","    #Final layer 4\n","    layer4_out = tf.add(vgg_layer4_1x1_bn, layer4_upsampled_bn, name='layer4_out')\n","    \n","    \n","    # Upsampled layer 3 using final layer 4\n","    layer3_upsampled4 = tf.layers.conv2d_transpose(layer4_out, vgg_layer3_out.get_shape().as_list()[-1], 4, \n","                                             strides= (2, 2), \n","                                             padding= 'same', \n","                                             kernel_initializer= tf.random_normal_initializer(stddev=0.01), \n","                                             kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3),\n","                                             name='layer3_upsampled4')\n","    \n","    #batch normalization on upsampled layer\n","    layer3_upsampled4_bn = tf.layers.batch_normalization(layer3_upsampled4, name=\"layer3_upsampled4_bn\")\n","    \n","        \n","    #layer3 taken from a 4x upsampling from layer7_1x1\n","    layer3_upsampled7 = tf.layers.conv2d_transpose(layer7_1x1, vgg_layer3_out.get_shape().as_list()[-1], 8, \n","                                             strides= (4, 4), \n","                                             padding= 'same', \n","                                             kernel_initializer= tf.random_normal_initializer(stddev=0.01), \n","                                             kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3),\n","                                             name='layer3_upsampled7')\n","    \n","    layer3_upsampled7_bn = tf.layers.batch_normalization(layer3_upsampled7, name=\"layer3_upsampled7_bn\")\n","    \n","    \n","    #1x1 Convolution on vgg_layer3_out\n","    vgg_layer3_1x1 = tf.layers.conv2d(vgg_layer3_out, filters=vgg_layer3_out.get_shape().as_list()[-1], kernel_size=(1, 1), strides=(1, 1),\n","                                          name=\"vgg_layer3_1x1\", activation=tf.nn.relu,\n","                                          kernel_initializer=tf.truncated_normal_initializer(stddev=0.01),\n","                                          kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3))\n","    \n","    #batch normalization on vgg layer\n","    vgg_layer3_1x1_bn = tf.layers.batch_normalization(vgg_layer3_1x1, name=\"vgg_layer3_1x1_bn\")\n","    \n","\n","    \n","    #Final Layer 3\n","    layer3_out = tf.add_n([vgg_layer3_1x1_bn, layer3_upsampled4_bn, layer3_upsampled7_bn], name='layer3_out')\n","    \n","    \n","    #Last Layer\n","    final_layer = tf.layers.conv2d_transpose(layer3_out, num_classes, 16,  \n","                                               strides= (8, 8), \n","                                               padding= 'same', \n","                                               kernel_initializer= tf.random_normal_initializer(stddev=0.01), \n","                                               kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3))\n","        \n","    return final_layer\n","\n","tests.test_layers(layers)\n","\n","\n","def optimize(nn_last_layer, correct_label, learning_rate, num_classes):\n","    \"\"\"\n","    Build the TensorFLow loss and optimizer operations.\n","    :param nn_last_layer: TF Tensor of the last layer in the neural network\n","    :param correct_label: TF Placeholder for the correct label image\n","    :param learning_rate: TF Placeholder for the learning rate\n","    :param num_classes: Number of classes to classify\n","    :return: Tuple of (logits, train_op, cross_entropy_loss)\n","    \"\"\"\n","    # TODO: Implement function\n","    \n","    logits = tf.reshape(nn_last_layer, (-1, num_classes))\n","    cross_entropy_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=nn_last_layer, labels=correct_label),\n","                                        name=\"cross_entropy\")\n","    regularization_loss = tf.losses.get_regularization_loss()\n","    total_loss = tf.add(cross_entropy_loss, regularization_loss)\n","    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n","    train_op = optimizer.minimize(total_loss)\n","    \n","    \n","    return logits , train_op, total_loss\n","\n","tests.test_optimize(optimize)\n","\n","def layers2(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes):\n","    \n","    # Since we are not using a vanilla vgg model, there is already a 1x1 convolution on the last layer.\n","    # The weights for the vgg_out layers are already trained so we dont overtrain them by stopping the gradient flow.\n","    vgg_layer7_out = tf.stop_gradient(vgg_layer7_out)\n","    vgg_layer4_out = tf.stop_gradient(vgg_layer4_out)\n","    vgg_layer3_out = tf.stop_gradient(vgg_layer3_out)\n","\n","    # Use a shorter variable name for simplicity\n","    layer3, layer4, layer7 = vgg_layer3_out, vgg_layer4_out, vgg_layer7_out\n","\n","    # Apply 1x1 convolution in place of fully connected layer\n","    fcn8 = tf.layers.conv2d(layer7, filters=num_classes, kernel_size=1, name=\"fcn8\")\n","    \n","    # Upsample fcn8 with size depth=(4096?) to match size of layer 4 so that we can add skip connection with 4th layer\n","    fcn9 = tf.layers.conv2d_transpose(fcn8, filters=layer4.get_shape().as_list()[-1],\n","    kernel_size=4, strides=(2, 2), padding='SAME', name=\"fcn9\")\n","    \n","    # Add a skip connection between current final layer fcn8 and 4th layer\n","    fcn9_skip_connected = tf.add(fcn9, layer4, name=\"fcn9_plus_vgg_layer4\")\n","    \n","    # Upsample again\n","    fcn10 = tf.layers.conv2d_transpose(fcn9_skip_connected, filters=layer3.get_shape().as_list()[-1],\n","    kernel_size=4, strides=(2, 2), padding='SAME', name=\"fcn10_conv2d\")\n","    \n","    # Add skip connection\n","    fcn10_skip_connected = tf.add(fcn10, layer3, name=\"fcn10_plus_vgg_layer3\")\n","    \n","    # Upsample again\n","    fcn11 = tf.layers.conv2d_transpose(fcn10_skip_connected, filters=num_classes,\n","    kernel_size=16, strides=(8, 8), padding='SAME', name=\"fcn11\")\n","\n","    return fcn11\n","\n","\n","\n","def train_nn(sess, epochs, batch_size, get_batches_fn, train_op, cross_entropy_loss, input_image,\n","             correct_label, keep_prob, learning_rate):\n","    \"\"\"\n","    Train neural network and print out the loss during training.\n","    :param sess: TF Session\n","    :param epochs: Number of epochs\n","    :param batch_size: Batch size\n","    :param get_batches_fn: Function to get batches of training data.  Call using get_batches_fn(batch_size)\n","    :param train_op: TF Operation to train the neural network\n","    :param cross_entropy_loss: TF Tensor for the amount of loss\n","    :param input_image: TF Placeholder for input images\n","    :param correct_label: TF Placeholder for label images\n","    :param keep_prob: TF Placeholder for dropout keep probability\n","    :param learning_rate: TF Placeholder for learning rate\n","    \"\"\"\n","    # TODO: Implement function\n","    sess.run(tf.global_variables_initializer())\n","\n","    \n","    print(\"Training...\")\n","    for i in tqdm(range(epochs)):\n","        print(\"EPOCH {} ...\".format(i+1))\n","        for image, label in get_batches_fn(batch_size):\n","            _, loss = sess.run([train_op, cross_entropy_loss], \n","                               feed_dict={input_image: image, correct_label: label, keep_prob: 0.5, learning_rate: 0.0005})\n","        print(\"Loss: = {:.3f}\".format(loss))\n","    \n","    print(\"Training Finished!!\")\n","    \n","\n","\n","def run():\n","    \n","    num_classes = 2\n","    image_shape = (160, 576)\n","    data_dir = './data'\n","    runs_dir = './runs2'\n","    model_dir = './models2'\n","    tests.test_for_kitti_dataset(data_dir)\n","\n","    # Download pretrained vgg model\n","    helper.maybe_download_pretrained_vgg(data_dir)\n","    \n","    ## gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.4)\n","\n","    # OPTIONAL: Train and Inference on the cityscapes dataset instead of the Kitti dataset.\n","    # You'll need a GPU with at least 10 teraFLOPS to train on.\n","    #  https://www.cityscapes-dataset.com/\n","    \n","            \n","    tf.reset_default_graph()\n","\n","    with tf.Session() as sess:\n","        # Path to vgg model\n","        vgg_path = os.path.join(data_dir, 'vgg')\n","        ## vgg_path = '.\\\\data\\\\vgg'\n","        # Create function to get batches\n","        get_batches_fn = helper.gen_batch_function(os.path.join(data_dir, 'data_road/training'), image_shape)\n","\n","\n","        # OPTIONAL: Augment Images for better results\n","        #  https://datascience.stackexchange.com/questions/5224/how-to-prepare-augment-images-for-neural-network\n","\n","        # TODO: Build NN using load_vgg, layers, and optimize function\n","        \n","        epochs = 20\n","        batch_size = 5\n","\n","        # TF placeholders\n","        correct_label = tf.placeholder(tf.int32, [None, None, None, num_classes], name='correct_label')\n","        learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n","\n","        input_image, keep_prob, vgg_layer3_out, vgg_layer4_out, vgg_layer7_out = load_vgg(sess, vgg_path)\n","\n","        nn_last_layer = layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes)\n","\n","        logits, train_op, cross_entropy_loss = optimize(nn_last_layer, correct_label, learning_rate, num_classes)\n","\n","        # TODO: Train NN using the train_nn function\n","        ## sess.run(tf.global_variables_initializer())\n","        saver = tf.train.Saver()\n","        \n","        train_nn(sess, epochs, batch_size, get_batches_fn, train_op, cross_entropy_loss, input_image,\n","                 correct_label, keep_prob, learning_rate)\n","        \n","        ## sess.run(tf.global_variables_initializer())\n","        ## saver = tf.train.Saver()\n","\n","        # TODO: Save inference data using helper.save_inference_samples\n","        helper.save_inference_samples(model_dir, runs_dir, data_dir, sess, image_shape, logits, keep_prob, input_image, saver)\n","        # OPTIONAL: Apply the trained model to a video\n","\n","\n","if __name__ == '__main__':\n","    run()\n","print(\"Done\")\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["TensorFlow Version: 1.10.0-rc1\n","Default GPU Device: /device:GPU:0\n","Tests Passed\n","Tests Passed\n","Tests Passed\n","Tests Passed\n","INFO:tensorflow:Restoring parameters from ./data/vgg/variables/variables\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/20 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training...\n","EPOCH 1 ...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n","  if issubdtype(ts, int):\n","/usr/local/lib/python3.6/dist-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n","  elif issubdtype(type(size), float):\n","  5%|▌         | 1/20 [08:56<2:50:02, 536.96s/it]"],"name":"stderr"},{"output_type":"stream","text":["Loss: = 0.503\n","EPOCH 2 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\r 10%|█         | 2/20 [10:09<1:31:22, 304.59s/it]"],"name":"stderr"},{"output_type":"stream","text":["Loss: = 0.423\n","EPOCH 3 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\r 15%|█▌        | 3/20 [11:23<1:04:32, 227.79s/it]"],"name":"stderr"},{"output_type":"stream","text":["Loss: = 0.332\n","EPOCH 4 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\r 20%|██        | 4/20 [12:36<50:24, 189.01s/it]  "],"name":"stderr"},{"output_type":"stream","text":["Loss: = 0.349\n","EPOCH 5 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\r 25%|██▌       | 5/20 [13:48<41:25, 165.68s/it]"],"name":"stderr"},{"output_type":"stream","text":["Loss: = 0.284\n","EPOCH 6 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\r 30%|███       | 6/20 [15:00<35:02, 150.15s/it]"],"name":"stderr"},{"output_type":"stream","text":["Loss: = 0.280\n","EPOCH 7 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\r 35%|███▌      | 7/20 [16:14<30:08, 139.15s/it]"],"name":"stderr"},{"output_type":"stream","text":["Loss: = 0.231\n","EPOCH 8 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\r 40%|████      | 8/20 [17:27<26:11, 130.95s/it]"],"name":"stderr"},{"output_type":"stream","text":["Loss: = 0.231\n","EPOCH 9 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\r 45%|████▌     | 9/20 [18:39<22:48, 124.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["Loss: = 0.245\n","EPOCH 10 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\r 50%|█████     | 10/20 [19:52<19:52, 119.25s/it]"],"name":"stderr"},{"output_type":"stream","text":["Loss: = 0.199\n","EPOCH 11 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\r 55%|█████▌    | 11/20 [21:05<17:15, 115.03s/it]"],"name":"stderr"},{"output_type":"stream","text":["Loss: = 0.203\n","EPOCH 12 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\r 60%|██████    | 12/20 [22:17<14:51, 111.50s/it]"],"name":"stderr"},{"output_type":"stream","text":["Loss: = 0.195\n","EPOCH 13 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\r 65%|██████▌   | 13/20 [23:31<12:40, 108.58s/it]"],"name":"stderr"},{"output_type":"stream","text":["Loss: = 0.185\n","EPOCH 14 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\r 70%|███████   | 14/20 [24:44<10:36, 106.01s/it]"],"name":"stderr"},{"output_type":"stream","text":["Loss: = 0.190\n","EPOCH 15 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\r 75%|███████▌  | 15/20 [25:57<08:39, 103.83s/it]"],"name":"stderr"},{"output_type":"stream","text":["Loss: = 0.168\n","EPOCH 16 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\r 80%|████████  | 16/20 [27:10<06:47, 101.90s/it]"],"name":"stderr"},{"output_type":"stream","text":["Loss: = 0.157\n","EPOCH 17 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\r 85%|████████▌ | 17/20 [28:22<05:00, 100.17s/it]"],"name":"stderr"},{"output_type":"stream","text":["Loss: = 0.159\n","EPOCH 18 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\r 90%|█████████ | 18/20 [29:36<03:17, 98.68s/it] "],"name":"stderr"},{"output_type":"stream","text":["Loss: = 0.169\n","EPOCH 19 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\r 95%|█████████▌| 19/20 [30:48<01:37, 97.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["Loss: = 0.163\n","EPOCH 20 ...\n"],"name":"stdout"},{"output_type":"stream","text":["\r100%|██████████| 20/20 [32:01<00:00, 96.08s/it]"],"name":"stderr"},{"output_type":"stream","text":["Loss: = 0.133\n","Training Finished!!\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"},{"output_type":"stream","text":["Training Finished. Saving test images to: ./runs2/1534107601.6213937\n","Done\n"],"name":"stdout"}]}]}