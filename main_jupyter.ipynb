{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please work4!!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 7775933944503524094, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 203348377\n",
       " locality {\n",
       "   bus_id: 1\n",
       " }\n",
       " incarnation: 11743895751215014819\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Please work4!!!\")\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "\n",
    "\n",
    "def get_available_gpus():\n",
    "\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "\n",
    "    return [x.physical_device_desc for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "\n",
    "\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown attribute: 'GeForce GTX 960M' in 'GeForce GTX 960M'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-dda603655ffd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mproject_tests\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtests\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GeForce GTX 960M'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't yield\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mdevice\u001b[1;34m(self, device_name_or_function)\u001b[0m\n\u001b[0;32m   3731\u001b[0m     if (device_name_or_function is not None and\n\u001b[0;32m   3732\u001b[0m         not callable(device_name_or_function)):\n\u001b[1;32m-> 3733\u001b[1;33m       \u001b[0mdevice_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice_name_or_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3734\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3735\u001b[0m       \u001b[0mdevice_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice_name_or_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\framework\\device.py\u001b[0m in \u001b[0;36mmerge_device\u001b[1;34m(spec)\u001b[0m\n\u001b[0;32m    280\u001b[0m   \"\"\"\n\u001b[0;32m    281\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDeviceSpec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 282\u001b[1;33m     \u001b[0mspec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDeviceSpec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_device_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[0mcurrent_device\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDeviceSpec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\framework\\device.py\u001b[0m in \u001b[0;36mfrom_string\u001b[1;34m(spec)\u001b[0m\n\u001b[0;32m    226\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mDeviceSpec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \"\"\"\n\u001b[1;32m--> 228\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mDeviceSpec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_from_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\framework\\device.py\u001b[0m in \u001b[0;36mparse_from_string\u001b[1;34m(self, spec)\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mly\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=g-explicit-bool-comparison\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown attribute: '%s' in '%s'\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown attribute: 'GeForce GTX 960M' in 'GeForce GTX 960M'"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import helper\n",
    "import warnings\n",
    "from distutils.version import LooseVersion\n",
    "import project_tests as tests\n",
    "import tensorflow as tf\n",
    "with tf.device('GeForce GTX 960M'):\n",
    "    \n",
    "\n",
    "\n",
    "    data_dir = './data'\n",
    "    \n",
    "    tests.test_for_kitti_dataset(data_dir)\n",
    "    # Download pretrained vgg model\n",
    "    helper.maybe_download_pretrained_vgg(data_dir)\n",
    "    \n",
    "    \n",
    "    def load_vgg(sess, vgg_path):\n",
    "        \"\"\"\n",
    "        Load Pretrained VGG Model into TensorFlow.\n",
    "        :param sess: TensorFlow Session\n",
    "        :param vgg_path: Path to vgg folder, containing \"variables/\" and \"saved_model.pb\"\n",
    "        :return: Tuple of Tensors from VGG model (image_input, keep_prob, layer3_out, layer4_out, layer7_out)\n",
    "        \"\"\"\n",
    "        # TODO: Implement function\n",
    "        #   Use tf.saved_model.loader.load to load the model and weights    \n",
    "        vgg_tag = 'vgg16'\n",
    "        vgg_input_tensor_name = 'image_input:0'\n",
    "        vgg_keep_prob_tensor_name = 'keep_prob:0'\n",
    "        vgg_layer3_out_tensor_name = 'layer3_out:0'\n",
    "        vgg_layer4_out_tensor_name = 'layer4_out:0'\n",
    "        vgg_layer7_out_tensor_name = 'layer7_out:0'\n",
    "        \n",
    "        tf.saved_model.loader.load(sess, [vgg_tag], vgg_path)\n",
    "        graph = tf.get_default_graph()\n",
    "        \n",
    "        image_input = graph.get_tensor_by_name(vgg_input_tensor_name)\n",
    "        \n",
    "        keep_prob = graph.get_tensor_by_name(vgg_keep_prob_tensor_name)\n",
    "        \n",
    "        layer3_out = graph.get_tensor_by_name(vgg_layer3_out_tensor_name)\n",
    "        \n",
    "        layer4_out = graph.get_tensor_by_name(vgg_layer4_out_tensor_name)\n",
    "        \n",
    "        layer7_out = graph.get_tensor_by_name(vgg_layer7_out_tensor_name)\n",
    "        \n",
    "        return image_input, keep_prob, layer3_out, layer4_out, layer7_out\n",
    "    \n",
    "    \n",
    "    tests.test_load_vgg(load_vgg, tf)\n",
    "    \n",
    "    print(\"loaded vgg model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: (1, 30, 30, 3)\n",
      "Same Shape: (1, 120, 120, 3)\n",
      "Valid Shape: (1, 124, 124, 3)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "k=8\n",
    "s=4\n",
    "\n",
    "def same_upsample(x):\n",
    "    return tf.layers.conv2d_transpose(x, 3, k, s, padding='SAME')\n",
    "\n",
    "def valid_upsample(x):\n",
    "    return tf.layers.conv2d_transpose(x, 3, k, s, padding='VALID')\n",
    "\n",
    "x = tf.constant(np.random.randn(1, 30, 30, 3), dtype=tf.float32)\n",
    "same_conv = same_upsample(x)\n",
    "valid_conv = valid_upsample(x)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    resultsame = sess.run(same_conv)\n",
    "    resultvalid = sess.run(valid_conv)\n",
    "    \n",
    "    print('Input Shape: {}'.format(x.get_shape()))\n",
    "    print('Same Shape: {}'.format(resultsame.shape))\n",
    "    print('Valid Shape: {}'.format(resultvalid.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n",
      "TensorFlow Version: 1.4.0\n",
      "Default GPU Device: /device:GPU:0\n",
      "All done\n",
      "[None, None, None, 256]\n",
      "[None, None, None, 512]\n",
      "[None, None, None, 4096]\n",
      "Tests Passed\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import tensorflow as tf\n",
    "import helper\n",
    "import warnings\n",
    "from distutils.version import LooseVersion\n",
    "import project_tests as tests\n",
    "import tensorflow as tf\n",
    "with tf.device('/GPU:1'):\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "\n",
    "\n",
    "    # Check TensorFlow Version\n",
    "    assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
    "    print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "    \n",
    "    # Check for a GPU\n",
    "    if not tf.test.gpu_device_name():\n",
    "        warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "    else:\n",
    "        print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "        \n",
    "    print(\"All done\")\n",
    "    \n",
    "    \n",
    "    def layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes):\n",
    "        \"\"\"\n",
    "        Create the layers for a fully convolutional network.  Build skip-layers using the vgg layers.\n",
    "        :param vgg_layer7_out: TF Tensor for VGG Layer 7 output\n",
    "        :param vgg_layer4_out: TF Tensor for VGG Layer 4 output\n",
    "        :param vgg_layer3_out: TF Tensor for VGG Layer 3 output\n",
    "        :param num_classes: Number of classes to classify\n",
    "        :return: The Tensor for the last layer of output\n",
    "        \"\"\"\n",
    "        # TODO: Implement function\n",
    "        vgg_layer3_out = tf.layers.batch_normalization(vgg_layer3_out, name=\"new_vgg_layer3_out\")\n",
    "        vgg_layer4_out = tf.layers.batch_normalization(vgg_layer4_out, name=\"new_vgg_layer4_out\")\n",
    "        vgg_layer7_out = tf.layers.batch_normalization(vgg_layer7_out, name=\"new_vgg_layer7_out\")\n",
    "        \n",
    "        print(vgg_layer3_out.get_shape().as_list())\n",
    "        print(vgg_layer4_out.get_shape().as_list())\n",
    "        print(vgg_layer7_out.get_shape().as_list())\n",
    "    \n",
    "        \n",
    "        #1x1 Convolution on layer 7\n",
    "        layer7_1x1 = tf.layers.conv2d(vgg_layer7_out, filters=num_classes, kernel_size=(1, 1), strides=(1, 1),\n",
    "                                              name='new_layer7_1x1_out', activation=tf.nn.relu,\n",
    "                                              kernel_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "                                              kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3))\n",
    "        \n",
    "        #upsampling on layer7_1x1\n",
    "        layer4_upsampled =  tf.layers.conv2d_transpose(layer7_1x1, vgg_layer4_out.get_shape().as_list()[-1], 4, \n",
    "                                                 strides= (2, 2), \n",
    "                                                 padding= 'same', \n",
    "                                                 kernel_initializer= tf.random_normal_initializer(stddev=0.01), \n",
    "                                                 kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3),\n",
    "                                                 name='layer4_upsampled')\n",
    "        \n",
    "        #batch normalization on upsampled layer\n",
    "        layer4_upsampled_bn = tf.layers.batch_normalization(layer4_upsampled, name=\"layer4_upsampled_bn\")\n",
    "        \n",
    "        #1x1 Convolution on vgg_layer4_out   \n",
    "        vgg_layer4_1x1 = tf.layers.conv2d(vgg_layer4_out, filters=vgg_layer4_out.get_shape().as_list()[-1], kernel_size=(1, 1), strides=(1, 1),\n",
    "                                              name=\"vgg_layer4_1x1\", activation=tf.nn.relu,\n",
    "                                              kernel_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "                                              kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3))\n",
    "        \n",
    "        #batch normalization on vgg layer\n",
    "        vgg_layer4_1x1_bn = tf.layers.batch_normalization(vgg_layer4_1x1, name=\"vgg_layer4_1x1_bn\")\n",
    "        \n",
    "        #Final layer 4\n",
    "        layer4_out = tf.add(vgg_layer4_1x1_bn, layer4_upsampled_bn, name='layer4_out')\n",
    "        \n",
    "        \n",
    "        # Upsampled layer 3 using final layer 4\n",
    "        layer3_upsampled4 = tf.layers.conv2d_transpose(layer4_out, vgg_layer3_out.get_shape().as_list()[-1], 4, \n",
    "                                                 strides= (2, 2), \n",
    "                                                 padding= 'same', \n",
    "                                                 kernel_initializer= tf.random_normal_initializer(stddev=0.01), \n",
    "                                                 kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3),\n",
    "                                                 name='layer3_upsampled')\n",
    "        \n",
    "        #batch normalization on upsampled layer\n",
    "        layer3_upsampled4_bn = tf.layers.batch_normalization(layer3_upsampled4, name=\"layer3_upsampled4_bn\")\n",
    "        \n",
    "            \n",
    "        #layer3 taken from a 4x upsampling from layer7_1x1\n",
    "        layer3_upsampled7 = tf.layers.conv2d_transpose(layer7_1x1, vgg_layer3_out.get_shape().as_list()[-1], 8, \n",
    "                                                 strides= (4, 4), \n",
    "                                                 padding= 'same', \n",
    "                                                 kernel_initializer= tf.random_normal_initializer(stddev=0.01), \n",
    "                                                 kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3),\n",
    "                                                 name='layer3_upsampled7')\n",
    "        \n",
    "        layer3_upsampled7_bn = tf.layers.batch_normalization(layer3_upsampled7, name=\"layer3_upsampled7_bn\")\n",
    "        \n",
    "        \n",
    "        #1x1 Convolution on vgg_layer3_out\n",
    "        vgg_layer3_1x1 = tf.layers.conv2d(vgg_layer3_out, filters=vgg_layer3_out.get_shape().as_list()[-1], kernel_size=(1, 1), strides=(1, 1),\n",
    "                                              name=\"vgg_layer3_1x1\", activation=tf.nn.relu,\n",
    "                                              kernel_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "                                              kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3))\n",
    "        \n",
    "        #batch normalization on vgg layer\n",
    "        vgg_layer3_1x1_bn = tf.layers.batch_normalization(vgg_layer3_1x1, name=\"vgg_layer3_1x1_bn\")\n",
    "        \n",
    "    \n",
    "        \n",
    "        #Final Layer 3\n",
    "        layer3_out = tf.add_n([vgg_layer3_1x1_bn, layer3_upsampled4_bn, layer3_upsampled7_bn], name='layer3_out')\n",
    "        \n",
    "        \n",
    "        #Last Layer\n",
    "        final_layer = tf.layers.conv2d_transpose(layer3_out, num_classes, 16,  \n",
    "                                                   strides= (8, 8), \n",
    "                                                   padding= 'same', \n",
    "                                                   kernel_initializer= tf.random_normal_initializer(stddev=0.01), \n",
    "                                                   kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3))\n",
    "            \n",
    "        return final_layer\n",
    "    \n",
    "    tests.test_layers(layers)\n",
    "    \n",
    "    print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train_nn function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNJNDJND\n",
      "TensorFlow Version: 1.4.0\n",
      "Default GPU Device: /device:GPU:0\n",
      "All done\n"
     ]
    }
   ],
   "source": [
    "print(\"FNJNDJND\")\n",
    "\n",
    "import os.path\n",
    "import tensorflow as tf\n",
    "import helper\n",
    "import warnings\n",
    "from distutils.version import LooseVersion\n",
    "import project_tests as tests\n",
    "\n",
    "with tf.device('/gpu:1'):\n",
    "    \n",
    "    # Check TensorFlow Version\n",
    "    assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
    "    print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "    \n",
    "    # Check for a GPU\n",
    "    if not tf.test.gpu_device_name():\n",
    "        warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "    else:\n",
    "        print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "        \n",
    "    print(\"All done\")\n",
    "    \n",
    "    def train_nn(sess, epochs, batch_size, get_batches_fn, train_op, cross_entropy_loss, input_image,\n",
    "                 correct_label, keep_prob, learning_rate):\n",
    "        \"\"\"\n",
    "        Train neural network and print out the loss during training.\n",
    "        :param sess: TF Session\n",
    "        :param epochs: Number of epochs\n",
    "        :param batch_size: Batch size\n",
    "        :param get_batches_fn: Function to get batches of training data.  Call using get_batches_fn(batch_size)\n",
    "        :param train_op: TF Operation to train the neural network\n",
    "        :param cross_entropy_loss: TF Tensor for the amount of loss\n",
    "        :param input_image: TF Placeholder for input images\n",
    "        :param correct_label: TF Placeholder for label images\n",
    "        :param keep_prob: TF Placeholder for dropout keep probability\n",
    "        :param learning_rate: TF Placeholder for learning rate\n",
    "        \"\"\"\n",
    "        # TODO: Implement function\n",
    "        ## sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "        \n",
    "        print(\"Training...\")\n",
    "        for i in range(epochs):\n",
    "            print(\"EPOCH {} ...\".format(i+1))\n",
    "            for image, label in get_batches_fn(batch_size):\n",
    "                _, loss = sess.run([train_op, cross_entropy_loss], \n",
    "                                   feed_dict={input_image: image, correct_label: label, keep_prob: 0.5, learning_rate: 0.0005})\n",
    "            print(\"Loss: = {:.3f}\".format(loss))\n",
    "        \n",
    "        print(\"Training Finished!!\")\n",
    "            \n",
    "    tests.test_train_nn(train_nn)\n",
    "    \n",
    "    print(\"Training DOne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.4.0\n",
      "Default GPU Device: /device:GPU:0\n",
      "All done\n",
      "Tests Passed\n",
      "load_vgg\n",
      "Tests Passed\n",
      "Tests Passed\n",
      "one more test left\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import tensorflow as tf\n",
    "import helper\n",
    "import warnings\n",
    "from distutils.version import LooseVersion\n",
    "import project_tests as tests\n",
    "\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "    \n",
    "print(\"All done\")\n",
    "\n",
    "def load_vgg(sess, vgg_path):\n",
    "    \"\"\"\n",
    "    Load Pretrained VGG Model into TensorFlow.\n",
    "    :param sess: TensorFlow Session\n",
    "    :param vgg_path: Path to vgg folder, containing \"variables/\" and \"saved_model.pb\"\n",
    "    :return: Tuple of Tensors from VGG model (image_input, keep_prob, layer3_out, layer4_out, layer7_out)\n",
    "    \"\"\"\n",
    "    # TODO: Implement function\n",
    "    #   Use tf.saved_model.loader.load to load the model and weights    \n",
    "    vgg_tag = 'vgg16'\n",
    "    vgg_input_tensor_name = 'image_input:0'\n",
    "    vgg_keep_prob_tensor_name = 'keep_prob:0'\n",
    "    vgg_layer3_out_tensor_name = 'layer3_out:0'\n",
    "    vgg_layer4_out_tensor_name = 'layer4_out:0'\n",
    "    vgg_layer7_out_tensor_name = 'layer7_out:0'\n",
    "    \n",
    "    tf.saved_model.loader.load(sess, [vgg_tag], vgg_path)\n",
    "    graph = tf.get_default_graph()\n",
    "    \n",
    "    image_input = graph.get_tensor_by_name(vgg_input_tensor_name)\n",
    "    \n",
    "    keep_prob = graph.get_tensor_by_name(vgg_keep_prob_tensor_name)\n",
    "    \n",
    "    layer3_out = graph.get_tensor_by_name(vgg_layer3_out_tensor_name)\n",
    "    \n",
    "    layer4_out = graph.get_tensor_by_name(vgg_layer4_out_tensor_name)\n",
    "    \n",
    "    layer7_out = graph.get_tensor_by_name(vgg_layer7_out_tensor_name)\n",
    "    \n",
    "    return image_input, keep_prob, layer3_out, layer4_out, layer7_out\n",
    "\n",
    "tests.test_load_vgg(load_vgg, tf)\n",
    "print(\"load_vgg\")\n",
    "\n",
    "\n",
    "\n",
    "def layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes):\n",
    "    \"\"\"\n",
    "    Create the layers for a fully convolutional network.  Build skip-layers using the vgg layers.\n",
    "    :param vgg_layer7_out: TF Tensor for VGG Layer 7 output\n",
    "    :param vgg_layer4_out: TF Tensor for VGG Layer 4 output\n",
    "    :param vgg_layer3_out: TF Tensor for VGG Layer 3 output\n",
    "    :param num_classes: Number of classes to classify\n",
    "    :return: The Tensor for the last layer of output\n",
    "    \"\"\"\n",
    "    # TODO: Implement function\n",
    "    vgg_layer3_out = tf.layers.batch_normalization(vgg_layer3_out, name=\"new_vgg_layer3_out\")\n",
    "    vgg_layer4_out = tf.layers.batch_normalization(vgg_layer4_out, name=\"new_vgg_layer4_out\")\n",
    "    vgg_layer7_out = tf.layers.batch_normalization(vgg_layer7_out, name=\"new_vgg_layer7_out\")\n",
    "    \n",
    "    #1x1 Convolution on layer 7\n",
    "    layer7_1x1 = tf.layers.conv2d(vgg_layer7_out, filters=num_classes, kernel_size=(1, 1), strides=(1, 1),\n",
    "                                          name='new_layer7_1x1_out', activation=tf.nn.relu,\n",
    "                                          kernel_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "                                          kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3))\n",
    "    \n",
    "    #upsampling on layer7_1x1\n",
    "    layer4_upsampled =  tf.layers.conv2d_transpose(layer7_1x1, vgg_layer4_out.get_shape().as_list()[-1], 4, \n",
    "                                             strides= (2, 2), \n",
    "                                             padding= 'same', \n",
    "                                             kernel_initializer= tf.random_normal_initializer(stddev=0.01), \n",
    "                                             kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3),\n",
    "                                             name='layer4_upsampled')\n",
    "    \n",
    "    #batch normalization on upsampled layer\n",
    "    layer4_upsampled_bn = tf.layers.batch_normalization(layer4_upsampled, name=\"layer4_upsampled_bn\")\n",
    "    \n",
    "    #1x1 Convolution on vgg_layer4_out   \n",
    "    vgg_layer4_1x1 = tf.layers.conv2d(vgg_layer4_out, filters=vgg_layer4_out.get_shape().as_list()[-1], kernel_size=(1, 1), strides=(1, 1),\n",
    "                                          name=\"vgg_layer4_1x1\", activation=tf.nn.relu,\n",
    "                                          kernel_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "                                          kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3))\n",
    "    \n",
    "    #batch normalization on vgg layer\n",
    "    vgg_layer4_1x1_bn = tf.layers.batch_normalization(vgg_layer4_1x1, name=\"vgg_layer4_1x1_bn\")\n",
    "    \n",
    "    #Final layer 4\n",
    "    layer4_out = tf.add(vgg_layer4_1x1_bn, layer4_upsampled_bn, name='layer4_out')\n",
    "    \n",
    "    \n",
    "    # Upsampled layer 3 using final layer 4\n",
    "    layer3_upsampled4 = tf.layers.conv2d_transpose(layer4_out, vgg_layer3_out.get_shape().as_list()[-1], 4, \n",
    "                                             strides= (2, 2), \n",
    "                                             padding= 'same', \n",
    "                                             kernel_initializer= tf.random_normal_initializer(stddev=0.01), \n",
    "                                             kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3),\n",
    "                                             name='layer3_upsampled')\n",
    "    \n",
    "    #batch normalization on upsampled layer\n",
    "    layer3_upsampled4_bn = tf.layers.batch_normalization(layer3_upsampled4, name=\"layer3_upsampled4_bn\")\n",
    "    \n",
    "        \n",
    "    #layer3 taken from a 4x upsampling from layer7_1x1\n",
    "    layer3_upsampled7 = tf.layers.conv2d_transpose(layer7_1x1, vgg_layer3_out.get_shape().as_list()[-1], 8, \n",
    "                                             strides= (4, 4), \n",
    "                                             padding= 'same', \n",
    "                                             kernel_initializer= tf.random_normal_initializer(stddev=0.01), \n",
    "                                             kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3),\n",
    "                                             name='layer3_upsampled7')\n",
    "    \n",
    "    layer3_upsampled7_bn = tf.layers.batch_normalization(layer3_upsampled7, name=\"layer3_upsampled7_bn\")\n",
    "    \n",
    "    \n",
    "    #1x1 Convolution on vgg_layer3_out\n",
    "    vgg_layer3_1x1 = tf.layers.conv2d(vgg_layer3_out, filters=vgg_layer3_out.get_shape().as_list()[-1], kernel_size=(1, 1), strides=(1, 1),\n",
    "                                          name=\"vgg_layer3_1x1\", activation=tf.nn.relu,\n",
    "                                          kernel_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "                                          kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3))\n",
    "    \n",
    "    #batch normalization on vgg layer\n",
    "    vgg_layer3_1x1_bn = tf.layers.batch_normalization(vgg_layer3_1x1, name=\"vgg_layer3_1x1_bn\")\n",
    "    \n",
    "\n",
    "    \n",
    "    #Final Layer 3\n",
    "    layer3_out = tf.add_n([vgg_layer3_1x1_bn, layer3_upsampled4_bn, layer3_upsampled7_bn], name='layer3_out')\n",
    "    \n",
    "    \n",
    "    #Last Layer\n",
    "    final_layer = tf.layers.conv2d_transpose(layer3_out, num_classes, 16,  \n",
    "                                               strides= (8, 8), \n",
    "                                               padding= 'same', \n",
    "                                               kernel_initializer= tf.random_normal_initializer(stddev=0.01), \n",
    "                                               kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3))\n",
    "        \n",
    "    return final_layer\n",
    "\n",
    "tests.test_layers(layers)\n",
    "\n",
    "def optimize(nn_last_layer, correct_label, learning_rate, num_classes):\n",
    "    \"\"\"\n",
    "    Build the TensorFLow loss and optimizer operations.\n",
    "    :param nn_last_layer: TF Tensor of the last layer in the neural network\n",
    "    :param correct_label: TF Placeholder for the correct label image\n",
    "    :param learning_rate: TF Placeholder for the learning rate\n",
    "    :param num_classes: Number of classes to classify\n",
    "    :return: Tuple of (logits, train_op, cross_entropy_loss)\n",
    "    \"\"\"\n",
    "    # TODO: Implement function\n",
    "    \n",
    "    logits = tf.reshape(nn_last_layer, (-1, num_classes))\n",
    "    cross_entropy_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=nn_last_layer, labels=correct_label),\n",
    "                                        name=\"cross_entropy\")\n",
    "    regularization_loss = tf.losses.get_regularization_loss()\n",
    "    total_loss = tf.add(cross_entropy_loss, regularization_loss)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "    train_op = optimizer.minimize(total_loss)\n",
    "    \n",
    "    \n",
    "    return logits , train_op, total_loss\n",
    "tests.test_optimize(optimize)\n",
    "\n",
    "print(\"one more test left\")\n",
    "\n",
    "def train_nn(sess, epochs, batch_size, get_batches_fn, train_op, cross_entropy_loss, input_image,\n",
    "             correct_label, keep_prob, learning_rate):\n",
    "    \"\"\"\n",
    "    Train neural network and print out the loss during training.\n",
    "    :param sess: TF Session\n",
    "    :param epochs: Number of epochs\n",
    "    :param batch_size: Batch size\n",
    "    :param get_batches_fn: Function to get batches of training data.  Call using get_batches_fn(batch_size)\n",
    "    :param train_op: TF Operation to train the neural network\n",
    "    :param cross_entropy_loss: TF Tensor for the amount of loss\n",
    "    :param input_image: TF Placeholder for input images\n",
    "    :param correct_label: TF Placeholder for label images\n",
    "    :param keep_prob: TF Placeholder for dropout keep probability\n",
    "    :param learning_rate: TF Placeholder for learning rate\n",
    "    \"\"\"\n",
    "    # TODO: Implement function\n",
    "    ## sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    for i in range(epochs):\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        for image, label in get_batches_fn(batch_size):\n",
    "            _, loss = sess.run([train_op, cross_entropy_loss], \n",
    "                               feed_dict={input_image: image, correct_label: label, keep_prob: 0.5, learning_rate: 0.0005})\n",
    "        print(\"Loss: = {:.3f}\".format(loss))\n",
    "\n",
    "tests.test_train_nn(train_nn)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.4.0\n",
      "Default GPU Device: /device:GPU:0\n",
      "Tests Passed\n",
      "Tests Passed\n",
      "Tests Passed\n",
      "Tests Passed\n",
      "INFO:tensorflow:Restoring parameters from b'./data\\\\vgg\\\\variables\\\\variables'\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor of shape [7,7,512,4096] and type float\n\t [[Node: fc6/weights/Adam/Initializer/zeros = Const[_class=[\"loc:@fc6/weights\"], dtype=DT_FLOAT, value=Tensor<type: float shape: [7,7,512,4096] values: [[[0 0 0]]]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'fc6/weights/Adam/Initializer/zeros', defined at:\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-5e945d2534d8>\", line 291, in <module>\n    run()\n  File \"<ipython-input-2-5e945d2534d8>\", line 273, in run\n    logits, train_op, cross_entropy_loss = optimize(nn_last_layer, correct_label, learning_rate, num_classes)\n  File \"<ipython-input-2-5e945d2534d8>\", line 164, in optimize\n    train_op = optimizer.minimize(total_loss)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 353, in minimize\n    name=name)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 474, in apply_gradients\n    self._create_slots([_get_variable_for(v) for v in var_list])\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\training\\adam.py\", line 136, in _create_slots\n    self._zeros_slot(v, \"m\", self._name)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 796, in _zeros_slot\n    named_slots[_var_key(var)] = slot_creator.create_zeros_slot(var, op_name)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 174, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 148, in create_slot_with_initializer\n    dtype)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 67, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1203, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1092, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 425, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 394, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 805, in _get_single_variable\n    constraint=constraint)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 213, in __init__\n    constraint=constraint)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 303, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 779, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py\", line 93, in __call__\n    return array_ops.zeros(shape, dtype)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1439, in zeros\n    output = constant(zero, shape=shape, dtype=dtype, name=name)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\", line 214, in constant\n    name=name).outputs[0]\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [7,7,512,4096] and type float\n\t [[Node: fc6/weights/Adam/Initializer/zeros = Const[_class=[\"loc:@fc6/weights\"], dtype=DT_FLOAT, value=Tensor<type: float shape: [7,7,512,4096] values: [[[0 0 0]]]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [7,7,512,4096] and type float\n\t [[Node: fc6/weights/Adam/Initializer/zeros = Const[_class=[\"loc:@fc6/weights\"], dtype=DT_FLOAT, value=Tensor<type: float shape: [7,7,512,4096] values: [[[0 0 0]]]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5e945d2534d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m     \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Done\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-5e945d2534d8>\u001b[0m in \u001b[0;36mrun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m         train_nn(sess, epochs, batch_size, get_batches_fn, train_op, cross_entropy_loss, input_image,\n\u001b[1;32m--> 280\u001b[1;33m                  correct_label, keep_prob, learning_rate)\n\u001b[0m\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[1;31m## sess.run(tf.global_variables_initializer())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-5e945d2534d8>\u001b[0m in \u001b[0;36mtrain_nn\u001b[1;34m(sess, epochs, batch_size, get_batches_fn, train_op, cross_entropy_loss, input_image, correct_label, keep_prob, learning_rate)\u001b[0m\n\u001b[0;32m    215\u001b[0m     \"\"\"\n\u001b[0;32m    216\u001b[0m     \u001b[1;31m# TODO: Implement function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor of shape [7,7,512,4096] and type float\n\t [[Node: fc6/weights/Adam/Initializer/zeros = Const[_class=[\"loc:@fc6/weights\"], dtype=DT_FLOAT, value=Tensor<type: float shape: [7,7,512,4096] values: [[[0 0 0]]]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'fc6/weights/Adam/Initializer/zeros', defined at:\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-5e945d2534d8>\", line 291, in <module>\n    run()\n  File \"<ipython-input-2-5e945d2534d8>\", line 273, in run\n    logits, train_op, cross_entropy_loss = optimize(nn_last_layer, correct_label, learning_rate, num_classes)\n  File \"<ipython-input-2-5e945d2534d8>\", line 164, in optimize\n    train_op = optimizer.minimize(total_loss)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 353, in minimize\n    name=name)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 474, in apply_gradients\n    self._create_slots([_get_variable_for(v) for v in var_list])\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\training\\adam.py\", line 136, in _create_slots\n    self._zeros_slot(v, \"m\", self._name)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\", line 796, in _zeros_slot\n    named_slots[_var_key(var)] = slot_creator.create_zeros_slot(var, op_name)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 174, in create_zeros_slot\n    colocate_with_primary=colocate_with_primary)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 148, in create_slot_with_initializer\n    dtype)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\training\\slot_creator.py\", line 67, in _create_slot_var\n    validate_shape=validate_shape)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1203, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1092, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 425, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 394, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 805, in _get_single_variable\n    constraint=constraint)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 213, in __init__\n    constraint=constraint)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 303, in _init_from_args\n    initial_value(), name=\"initial_value\", dtype=dtype)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 779, in <lambda>\n    shape.as_list(), dtype=dtype, partition_info=partition_info)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py\", line 93, in __call__\n    return array_ops.zeros(shape, dtype)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1439, in zeros\n    output = constant(zero, shape=shape, dtype=dtype, name=name)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\", line 214, in constant\n    name=name).outputs[0]\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor of shape [7,7,512,4096] and type float\n\t [[Node: fc6/weights/Adam/Initializer/zeros = Const[_class=[\"loc:@fc6/weights\"], dtype=DT_FLOAT, value=Tensor<type: float shape: [7,7,512,4096] values: [[[0 0 0]]]...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import helper\n",
    "import warnings\n",
    "from distutils.version import LooseVersion\n",
    "import project_tests as tests\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "    # Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "    \n",
    "\n",
    "def load_vgg(sess, vgg_path):\n",
    "    \"\"\"\n",
    "    Load Pretrained VGG Model into TensorFlow.\n",
    "    :param sess: TensorFlow Session\n",
    "    :param vgg_path: Path to vgg folder, containing \"variables/\" and \"saved_model.pb\"\n",
    "    :return: Tuple of Tensors from VGG model (image_input, keep_prob, layer3_out, layer4_out, layer7_out)\n",
    "    \"\"\"\n",
    "    # TODO: Implement function\n",
    "    #   Use tf.saved_model.loader.load to load the model and weights    \n",
    "    vgg_tag = 'vgg16'\n",
    "    vgg_input_tensor_name = 'image_input:0'\n",
    "    vgg_keep_prob_tensor_name = 'keep_prob:0'\n",
    "    vgg_layer3_out_tensor_name = 'layer3_out:0'\n",
    "    vgg_layer4_out_tensor_name = 'layer4_out:0'\n",
    "    vgg_layer7_out_tensor_name = 'layer7_out:0'\n",
    "    \n",
    "    tf.saved_model.loader.load(sess, [vgg_tag], vgg_path)\n",
    "    graph = tf.get_default_graph()\n",
    "    \n",
    "    image_input = graph.get_tensor_by_name(vgg_input_tensor_name)\n",
    "    \n",
    "    keep_prob = graph.get_tensor_by_name(vgg_keep_prob_tensor_name)\n",
    "    \n",
    "    layer3_out = graph.get_tensor_by_name(vgg_layer3_out_tensor_name)\n",
    "    \n",
    "    layer4_out = graph.get_tensor_by_name(vgg_layer4_out_tensor_name)\n",
    "    \n",
    "    layer7_out = graph.get_tensor_by_name(vgg_layer7_out_tensor_name)\n",
    "    \n",
    "    return image_input, keep_prob, layer3_out, layer4_out, layer7_out\n",
    "\n",
    "tests.test_load_vgg(load_vgg, tf)\n",
    "\n",
    "def layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes):\n",
    "    \"\"\"\n",
    "    Create the layers for a fully convolutional network.  Build skip-layers using the vgg layers.\n",
    "    :param vgg_layer7_out: TF Tensor for VGG Layer 7 output\n",
    "    :param vgg_layer4_out: TF Tensor for VGG Layer 4 output\n",
    "    :param vgg_layer3_out: TF Tensor for VGG Layer 3 output\n",
    "    :param num_classes: Number of classes to classify\n",
    "    :return: The Tensor for the last layer of output\n",
    "    \"\"\"\n",
    "    # TODO: Implement function\n",
    "    vgg_layer3_out = tf.layers.batch_normalization(vgg_layer3_out, name=\"new_vgg_layer3_out\")\n",
    "    vgg_layer4_out = tf.layers.batch_normalization(vgg_layer4_out, name=\"new_vgg_layer4_out\")\n",
    "    vgg_layer7_out = tf.layers.batch_normalization(vgg_layer7_out, name=\"new_vgg_layer7_out\")\n",
    "    \n",
    "    #1x1 Convolution on layer 7\n",
    "    layer7_1x1 = tf.layers.conv2d(vgg_layer7_out, filters=num_classes, kernel_size=(1, 1), strides=(1, 1),\n",
    "                                          name='new_layer7_1x1_out', activation=tf.nn.relu,\n",
    "                                          kernel_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "                                          kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3))\n",
    "    \n",
    "    #upsampling on layer7_1x1\n",
    "    layer4_upsampled =  tf.layers.conv2d_transpose(layer7_1x1, vgg_layer4_out.get_shape().as_list()[-1], 4, \n",
    "                                             strides= (2, 2), \n",
    "                                             padding= 'same', \n",
    "                                             kernel_initializer= tf.random_normal_initializer(stddev=0.01), \n",
    "                                             kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3),\n",
    "                                             name='layer4_upsampled')\n",
    "    \n",
    "    #batch normalization on upsampled layer\n",
    "    layer4_upsampled_bn = tf.layers.batch_normalization(layer4_upsampled, name=\"layer4_upsampled_bn\")\n",
    "    \n",
    "    #1x1 Convolution on vgg_layer4_out   \n",
    "    vgg_layer4_1x1 = tf.layers.conv2d(vgg_layer4_out, filters=vgg_layer4_out.get_shape().as_list()[-1], kernel_size=(1, 1), strides=(1, 1),\n",
    "                                          name=\"vgg_layer4_1x1\", activation=tf.nn.relu,\n",
    "                                          kernel_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "                                          kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3))\n",
    "    \n",
    "    #batch normalization on vgg layer\n",
    "    vgg_layer4_1x1_bn = tf.layers.batch_normalization(vgg_layer4_1x1, name=\"vgg_layer4_1x1_bn\")\n",
    "    \n",
    "    #Final layer 4\n",
    "    layer4_out = tf.add(vgg_layer4_1x1_bn, layer4_upsampled_bn, name='layer4_out')\n",
    "    \n",
    "    \n",
    "    # Upsampled layer 3 using final layer 4\n",
    "    layer3_upsampled4 = tf.layers.conv2d_transpose(layer4_out, vgg_layer3_out.get_shape().as_list()[-1], 4, \n",
    "                                             strides= (2, 2), \n",
    "                                             padding= 'same', \n",
    "                                             kernel_initializer= tf.random_normal_initializer(stddev=0.01), \n",
    "                                             kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3),\n",
    "                                             name='layer3_upsampled')\n",
    "    \n",
    "    #batch normalization on upsampled layer\n",
    "    layer3_upsampled4_bn = tf.layers.batch_normalization(layer3_upsampled4, name=\"layer3_upsampled4_bn\")\n",
    "    \n",
    "        \n",
    "    #layer3 taken from a 4x upsampling from layer7_1x1\n",
    "    layer3_upsampled7 = tf.layers.conv2d_transpose(layer7_1x1, vgg_layer3_out.get_shape().as_list()[-1], 8, \n",
    "                                             strides= (4, 4), \n",
    "                                             padding= 'same', \n",
    "                                             kernel_initializer= tf.random_normal_initializer(stddev=0.01), \n",
    "                                             kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3),\n",
    "                                             name='layer3_upsampled7')\n",
    "    \n",
    "    layer3_upsampled7_bn = tf.layers.batch_normalization(layer3_upsampled7, name=\"layer3_upsampled7_bn\")\n",
    "    \n",
    "    \n",
    "    #1x1 Convolution on vgg_layer3_out\n",
    "    vgg_layer3_1x1 = tf.layers.conv2d(vgg_layer3_out, filters=vgg_layer3_out.get_shape().as_list()[-1], kernel_size=(1, 1), strides=(1, 1),\n",
    "                                          name=\"vgg_layer3_1x1\", activation=tf.nn.relu,\n",
    "                                          kernel_initializer=tf.truncated_normal_initializer(stddev=0.01),\n",
    "                                          kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3))\n",
    "    \n",
    "    #batch normalization on vgg layer\n",
    "    vgg_layer3_1x1_bn = tf.layers.batch_normalization(vgg_layer3_1x1, name=\"vgg_layer3_1x1_bn\")\n",
    "    \n",
    "\n",
    "    \n",
    "    #Final Layer 3\n",
    "    layer3_out = tf.add_n([vgg_layer3_1x1_bn, layer3_upsampled4_bn, layer3_upsampled7_bn], name='layer3_out')\n",
    "    \n",
    "    \n",
    "    #Last Layer\n",
    "    final_layer = tf.layers.conv2d_transpose(layer3_out, num_classes, 16,  \n",
    "                                               strides= (8, 8), \n",
    "                                               padding= 'same', \n",
    "                                               kernel_initializer= tf.random_normal_initializer(stddev=0.01), \n",
    "                                               kernel_regularizer= tf.contrib.layers.l2_regularizer(1e-3))\n",
    "        \n",
    "    return final_layer\n",
    "\n",
    "tests.test_layers(layers)\n",
    "\n",
    "\n",
    "def optimize(nn_last_layer, correct_label, learning_rate, num_classes):\n",
    "    \"\"\"\n",
    "    Build the TensorFLow loss and optimizer operations.\n",
    "    :param nn_last_layer: TF Tensor of the last layer in the neural network\n",
    "    :param correct_label: TF Placeholder for the correct label image\n",
    "    :param learning_rate: TF Placeholder for the learning rate\n",
    "    :param num_classes: Number of classes to classify\n",
    "    :return: Tuple of (logits, train_op, cross_entropy_loss)\n",
    "    \"\"\"\n",
    "    # TODO: Implement function\n",
    "    \n",
    "    logits = tf.reshape(nn_last_layer, (-1, num_classes))\n",
    "    cross_entropy_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=nn_last_layer, labels=correct_label),\n",
    "                                        name=\"cross_entropy\")\n",
    "    regularization_loss = tf.losses.get_regularization_loss()\n",
    "    total_loss = tf.add(cross_entropy_loss, regularization_loss)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "    train_op = optimizer.minimize(total_loss)\n",
    "    \n",
    "    \n",
    "    return logits , train_op, total_loss\n",
    "\n",
    "tests.test_optimize(optimize)\n",
    "\n",
    "def layers2(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes):\n",
    "\n",
    "    # Use a shorter variable name for simplicity\n",
    "    layer3, layer4, layer7 = vgg_layer3_out, vgg_layer4_out, vgg_layer7_out\n",
    "\n",
    "    # Apply 1x1 convolution in place of fully connected layer\n",
    "    fcn8 = tf.layers.conv2d(layer7, filters=num_classes, kernel_size=1, name=\"fcn8\")\n",
    "    \n",
    "    # Upsample fcn8 with size depth=(4096?) to match size of layer 4 so that we can add skip connection with 4th layer\n",
    "    fcn9 = tf.layers.conv2d_transpose(fcn8, filters=layer4.get_shape().as_list()[-1],\n",
    "    kernel_size=4, strides=(2, 2), padding='SAME', name=\"fcn9\")\n",
    "    \n",
    "    # Add a skip connection between current final layer fcn8 and 4th layer\n",
    "    fcn9_skip_connected = tf.add(fcn9, layer4, name=\"fcn9_plus_vgg_layer4\")\n",
    "    \n",
    "    # Upsample again\n",
    "    fcn10 = tf.layers.conv2d_transpose(fcn9_skip_connected, filters=layer3.get_shape().as_list()[-1],\n",
    "    kernel_size=4, strides=(2, 2), padding='SAME', name=\"fcn10_conv2d\")\n",
    "    \n",
    "    # Add skip connection\n",
    "    fcn10_skip_connected = tf.add(fcn10, layer3, name=\"fcn10_plus_vgg_layer3\")\n",
    "    \n",
    "    # Upsample again\n",
    "    fcn11 = tf.layers.conv2d_transpose(fcn10_skip_connected, filters=num_classes,\n",
    "    kernel_size=16, strides=(8, 8), padding='SAME', name=\"fcn11\")\n",
    "\n",
    "    return fcn11\n",
    "\n",
    "\n",
    "\n",
    "def train_nn(sess, epochs, batch_size, get_batches_fn, train_op, cross_entropy_loss, input_image,\n",
    "             correct_label, keep_prob, learning_rate):\n",
    "    \"\"\"\n",
    "    Train neural network and print out the loss during training.\n",
    "    :param sess: TF Session\n",
    "    :param epochs: Number of epochs\n",
    "    :param batch_size: Batch size\n",
    "    :param get_batches_fn: Function to get batches of training data.  Call using get_batches_fn(batch_size)\n",
    "    :param train_op: TF Operation to train the neural network\n",
    "    :param cross_entropy_loss: TF Tensor for the amount of loss\n",
    "    :param input_image: TF Placeholder for input images\n",
    "    :param correct_label: TF Placeholder for label images\n",
    "    :param keep_prob: TF Placeholder for dropout keep probability\n",
    "    :param learning_rate: TF Placeholder for learning rate\n",
    "    \"\"\"\n",
    "    # TODO: Implement function\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    for i in tqdm(range(epochs)):\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        for image, label in get_batches_fn(batch_size):\n",
    "            _, loss = sess.run([train_op, cross_entropy_loss], \n",
    "                               feed_dict={input_image: image, correct_label: label, keep_prob: 0.5, learning_rate: 0.0005})\n",
    "        print(\"Loss: = {:.3f}\".format(loss))\n",
    "    \n",
    "    print(\"Training Finished!!\")\n",
    "    \n",
    "\n",
    "\n",
    "def run():\n",
    "    \n",
    "    num_classes = 2\n",
    "    image_shape = (160, 576)\n",
    "    data_dir = './data'\n",
    "    runs_dir = './runs'\n",
    "    model_dir = './models'\n",
    "    tests.test_for_kitti_dataset(data_dir)\n",
    "\n",
    "    # Download pretrained vgg model\n",
    "    helper.maybe_download_pretrained_vgg(data_dir)\n",
    "    \n",
    "    ## gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.4)\n",
    "\n",
    "    # OPTIONAL: Train and Inference on the cityscapes dataset instead of the Kitti dataset.\n",
    "    # You'll need a GPU with at least 10 teraFLOPS to train on.\n",
    "    #  https://www.cityscapes-dataset.com/\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        # Path to vgg model\n",
    "        vgg_path = os.path.join(data_dir, 'vgg')\n",
    "        ## vgg_path = '.\\\\data\\\\vgg'\n",
    "        # Create function to get batches\n",
    "        get_batches_fn = helper.gen_batch_function(os.path.join(data_dir, 'data_road/training'), image_shape)\n",
    "\n",
    "        # OPTIONAL: Augment Images for better results\n",
    "        #  https://datascience.stackexchange.com/questions/5224/how-to-prepare-augment-images-for-neural-network\n",
    "\n",
    "        # TODO: Build NN using load_vgg, layers, and optimize function\n",
    "        \n",
    "        epochs = 20\n",
    "        batch_size = 3\n",
    "\n",
    "        # TF placeholders\n",
    "        correct_label = tf.placeholder(tf.int32, [None, None, None, num_classes], name='correct_label')\n",
    "        learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "\n",
    "        input_image, keep_prob, vgg_layer3_out, vgg_layer4_out, vgg_layer7_out = load_vgg(sess, vgg_path)\n",
    "\n",
    "        nn_last_layer = layers2(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes)\n",
    "\n",
    "        logits, train_op, cross_entropy_loss = optimize(nn_last_layer, correct_label, learning_rate, num_classes)\n",
    "\n",
    "        # TODO: Train NN using the train_nn function\n",
    "        ## sess.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        train_nn(sess, epochs, batch_size, get_batches_fn, train_op, cross_entropy_loss, input_image,\n",
    "                 correct_label, keep_prob, learning_rate)\n",
    "        \n",
    "        ## sess.run(tf.global_variables_initializer())\n",
    "        ## saver = tf.train.Saver()\n",
    "\n",
    "        # TODO: Save inference data using helper.save_inference_samples\n",
    "        helper.save_inference_samples(model_dir, runs_dir, data_dir, sess, image_shape, logits, keep_prob, input_image, saver)\n",
    "        # OPTIONAL: Apply the trained model to a video\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    run()\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.4.0\n",
      "Default GPU Device: /device:GPU:0\n",
      "Tests Passed\n",
      "Tests Passed\n",
      "Tests Passed\n",
      "INFO:tensorflow:Restoring parameters from b'./data\\\\vgg\\\\variables\\\\variables'\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[7,7,512,4096]\n\t [[Node: save/Assign_27 = Assign[T=DT_FLOAT, _class=[\"loc:@fc6/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](fc6/weights, save/RestoreV2_27/_7)]]\n\nCaused by op 'save/Assign_27', defined at:\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-5e945d2534d8>\", line 291, in <module>\n    run()\n  File \"<ipython-input-2-5e945d2534d8>\", line 269, in run\n    input_image, keep_prob, vgg_layer3_out, vgg_layer4_out, vgg_layer7_out = load_vgg(sess, vgg_path)\n  File \"<ipython-input-2-5e945d2534d8>\", line 36, in load_vgg\n    tf.saved_model.loader.load(sess, [vgg_tag], vgg_path)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\", line 216, in load\n    saver = tf_saver.import_meta_graph(meta_graph_def_to_load, **saver_kwargs)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1810, in import_meta_graph\n    **kwargs)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\framework\\meta_graph.py\", line 660, in import_scoped_meta_graph\n    producer_op_list=producer_op_list)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 313, in import_graph_def\n    op_def=op_def)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[7,7,512,4096]\n\t [[Node: save/Assign_27 = Assign[T=DT_FLOAT, _class=[\"loc:@fc6/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](fc6/weights, save/RestoreV2_27/_7)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 473\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    474\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[7,7,512,4096]\n\t [[Node: save/Assign_27 = Assign[T=DT_FLOAT, _class=[\"loc:@fc6/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](fc6/weights, save/RestoreV2_27/_7)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-8d9910744cd2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 465\u001b[1;33m     \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-8d9910744cd2>\u001b[0m in \u001b[0;36mrun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[1;31m# Getting layers from vgg.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 417\u001b[1;33m         \u001b[0minput_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer3_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer4_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer7_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_vgg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvgg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-8d9910744cd2>\u001b[0m in \u001b[0;36mload_vgg\u001b[1;34m(sess, vgg_path)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvgg_tag\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvgg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(sess, tags, export_dir, **saver_kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m       \u001b[1;31m# Restore the variables using the built saver in the provided session.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m       \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m       tf_logging.info(\"The specified SavedModel has no variables; no \"\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1664\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1665\u001b[0m       sess.run(self.saver_def.restore_op_name,\n\u001b[1;32m-> 1666\u001b[1;33m                {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[0;32m   1667\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1668\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_eager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[7,7,512,4096]\n\t [[Node: save/Assign_27 = Assign[T=DT_FLOAT, _class=[\"loc:@fc6/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](fc6/weights, save/RestoreV2_27/_7)]]\n\nCaused by op 'save/Assign_27', defined at:\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-5e945d2534d8>\", line 291, in <module>\n    run()\n  File \"<ipython-input-2-5e945d2534d8>\", line 269, in run\n    input_image, keep_prob, vgg_layer3_out, vgg_layer4_out, vgg_layer7_out = load_vgg(sess, vgg_path)\n  File \"<ipython-input-2-5e945d2534d8>\", line 36, in load_vgg\n    tf.saved_model.loader.load(sess, [vgg_tag], vgg_path)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\", line 216, in load\n    saver = tf_saver.import_meta_graph(meta_graph_def_to_load, **saver_kwargs)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1810, in import_meta_graph\n    **kwargs)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\framework\\meta_graph.py\", line 660, in import_scoped_meta_graph\n    producer_op_list=producer_op_list)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\framework\\importer.py\", line 313, in import_graph_def\n    op_def=op_def)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\Siddharth Singi\\Miniconda3\\envs\\carnd-advdl-odlab\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[7,7,512,4096]\n\t [[Node: save/Assign_27 = Assign[T=DT_FLOAT, _class=[\"loc:@fc6/weights\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](fc6/weights, save/RestoreV2_27/_7)]]\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import helper\n",
    "\n",
    "import warnings\n",
    "\n",
    "from distutils.version import LooseVersion\n",
    "\n",
    "import project_tests as tests\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Check TensorFlow Version\n",
    "\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
    "\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "\n",
    "\n",
    "# Check for a GPU\n",
    "\n",
    "if not tf.test.gpu_device_name():\n",
    "\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "\n",
    "else:\n",
    "\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_vgg(sess, vgg_path):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Load Pretrained VGG Model into TensorFlow.\n",
    "\n",
    "    :param sess: TensorFlow Session\n",
    "\n",
    "    :param vgg_path: Path to vgg folder, containing \"variables/\" and \"saved_model.pb\"\n",
    "\n",
    "    :return: Tuple of Tensors from VGG model (image_input, keep_prob, layer3_out, layer4_out, layer7_out)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement function\n",
    "\n",
    "    #   Use tf.saved_model.loader.load to load the model and weights\n",
    "\n",
    "    vgg_tag = 'vgg16'\n",
    "\n",
    "    vgg_input_tensor_name = 'image_input:0'\n",
    "\n",
    "    vgg_keep_prob_tensor_name = 'keep_prob:0'\n",
    "\n",
    "    vgg_layer3_out_tensor_name = 'layer3_out:0'\n",
    "\n",
    "    vgg_layer4_out_tensor_name = 'layer4_out:0'\n",
    "\n",
    "    vgg_layer7_out_tensor_name = 'layer7_out:0'\n",
    "\n",
    "\n",
    "\n",
    "    tf.saved_model.loader.load(sess, [vgg_tag], vgg_path)\n",
    "\n",
    "    graph = tf.get_default_graph()\n",
    "\n",
    "    input_layer = graph.get_tensor_by_name(vgg_input_tensor_name)\n",
    "\n",
    "    keep_prob = graph.get_tensor_by_name(vgg_keep_prob_tensor_name)\n",
    "\n",
    "    layer3 = graph.get_tensor_by_name(vgg_layer3_out_tensor_name)\n",
    "\n",
    "    layer4 = graph.get_tensor_by_name(vgg_layer4_out_tensor_name)\n",
    "\n",
    "    layer7 = graph.get_tensor_by_name(vgg_layer7_out_tensor_name)\n",
    "\n",
    "\n",
    "\n",
    "    return input_layer, keep_prob, layer3, layer4, layer7\n",
    "\n",
    "\n",
    "\n",
    "tests.test_load_vgg(load_vgg, tf)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def layers(vgg_layer3_out, vgg_layer4_out, vgg_layer7_out, num_classes):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Create the layers for a fully convolutional network.  Build skip-layers using the vgg layers.\n",
    "\n",
    "    :param vgg_layer7_out: TF Tensor for VGG Layer 3 output\n",
    "\n",
    "    :param vgg_layer4_out: TF Tensor for VGG Layer 4 output\n",
    "\n",
    "    :param vgg_layer3_out: TF Tensor for VGG Layer 7 output\n",
    "\n",
    "    :param num_classes: Number of classes to classify\n",
    "\n",
    "    :return: The Tensor for the last layer of output\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    weights_initializer_stddev = 0.01\n",
    "\n",
    "    weights_regularized_l2 = 1e-3\n",
    "\n",
    "    # TODO: Implement function\n",
    "\n",
    "    # Convolutional 1x1 to mantain space information.\n",
    "\n",
    "    conv_1x1_of_7 = tf.layers.conv2d(vgg_layer7_out,\n",
    "\n",
    "                                     num_classes,\n",
    "\n",
    "                                     1, # kernel_size\n",
    "\n",
    "                                     padding = 'same',\n",
    "\n",
    "                                     kernel_initializer = tf.random_normal_initializer(stddev=weights_initializer_stddev),\n",
    "\n",
    "                                     kernel_regularizer= tf.contrib.layers.l2_regularizer(weights_regularized_l2),\n",
    "\n",
    "                                     name='conv_1x1_of_7')\n",
    "\n",
    "    # Upsample deconvolution x 2\n",
    "\n",
    "    first_upsamplex2 = tf.layers.conv2d_transpose(conv_1x1_of_7,\n",
    "\n",
    "                                                  num_classes,\n",
    "\n",
    "                                                  4, # kernel_size\n",
    "\n",
    "                                                  strides= (2, 2),\n",
    "\n",
    "                                                  padding= 'same',\n",
    "\n",
    "                                                  kernel_initializer = tf.random_normal_initializer(stddev=weights_initializer_stddev),\n",
    "\n",
    "                                                  kernel_regularizer= tf.contrib.layers.l2_regularizer(weights_regularized_l2),\n",
    "\n",
    "                                                  name='first_upsamplex2')\n",
    "\n",
    "    conv_1x1_of_4 = tf.layers.conv2d(vgg_layer4_out,\n",
    "\n",
    "                                     num_classes,\n",
    "\n",
    "                                     1, # kernel_size\n",
    "\n",
    "                                     padding = 'same',\n",
    "\n",
    "                                     kernel_initializer = tf.random_normal_initializer(stddev=weights_initializer_stddev),\n",
    "\n",
    "                                     kernel_regularizer= tf.contrib.layers.l2_regularizer(weights_regularized_l2),\n",
    "\n",
    "                                     name='conv_1x1_of_4')\n",
    "\n",
    "    # Adding skip layer.\n",
    "\n",
    "    first_skip = tf.add(first_upsamplex2, conv_1x1_of_4, name='first_skip')\n",
    "\n",
    "    # Upsample deconvolutions x 2.\n",
    "\n",
    "    second_upsamplex2 = tf.layers.conv2d_transpose(first_skip,\n",
    "\n",
    "                                                   num_classes,\n",
    "\n",
    "                                                   4, # kernel_size\n",
    "\n",
    "                                                   strides= (2, 2),\n",
    "\n",
    "                                                   padding= 'same',\n",
    "\n",
    "                                                   kernel_initializer = tf.random_normal_initializer(stddev=weights_initializer_stddev),\n",
    "\n",
    "                                                   kernel_regularizer= tf.contrib.layers.l2_regularizer(weights_regularized_l2),\n",
    "\n",
    "                                                   name='second_upsamplex2')\n",
    "\n",
    "    conv_1x1_of_3 = tf.layers.conv2d(vgg_layer3_out,\n",
    "\n",
    "                                     num_classes,\n",
    "\n",
    "                                     1, # kernel_size\n",
    "\n",
    "                                     padding = 'same',\n",
    "\n",
    "                                     kernel_initializer = tf.random_normal_initializer(stddev=weights_initializer_stddev),\n",
    "\n",
    "                                     kernel_regularizer= tf.contrib.layers.l2_regularizer(weights_regularized_l2),\n",
    "\n",
    "                                     name='conv_1x1_of_3')\n",
    "\n",
    "    # Adding skip layer.\n",
    "\n",
    "    second_skip = tf.add(second_upsamplex2, conv_1x1_of_3, name='second_skip')\n",
    "\n",
    "    # Upsample deconvolution x 8.\n",
    "\n",
    "    third_upsamplex8 = tf.layers.conv2d_transpose(second_skip, num_classes, 16,\n",
    "\n",
    "                                                  strides= (8, 8),\n",
    "\n",
    "                                                  padding= 'same',\n",
    "\n",
    "                                                  kernel_initializer = tf.random_normal_initializer(stddev=weights_initializer_stddev),\n",
    "\n",
    "                                                  kernel_regularizer= tf.contrib.layers.l2_regularizer(weights_regularized_l2),\n",
    "\n",
    "                                                  name='third_upsamplex8')\n",
    "\n",
    "    return third_upsamplex8\n",
    "\n",
    "tests.test_layers(layers)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def optimize(nn_last_layer, correct_label, learning_rate, num_classes):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Build the TensorFLow loss and optimizer operations.\n",
    "\n",
    "    :param nn_last_layer: TF Tensor of the last layer in the neural network\n",
    "\n",
    "    :param correct_label: TF Placeholder for the correct label image\n",
    "\n",
    "    :param learning_rate: TF Placeholder for the learning rate\n",
    "\n",
    "    :param num_classes: Number of classes to classify\n",
    "\n",
    "    :return: Tuple of (logits, train_op, cross_entropy_loss)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement function\n",
    "\n",
    "    # create logits : 2D tensor where each row represents a pixel and each column a class.\n",
    "\n",
    "    logits = tf.reshape(nn_last_layer, (-1, num_classes))\n",
    "\n",
    "    correct_label = tf.reshape(correct_label, (-1,num_classes))\n",
    "\n",
    "    # create loss function.\n",
    "\n",
    "    cross_entropy_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits= logits, labels= correct_label))\n",
    "\n",
    "    # Define optimizer. Adam in this case to have variable learning rate.\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate= learning_rate)\n",
    "\n",
    "    # Apply optimizer to the loss function.\n",
    "\n",
    "    train_op = optimizer.minimize(cross_entropy_loss)\n",
    "\n",
    "\n",
    "\n",
    "    return logits, train_op, cross_entropy_loss\n",
    "\n",
    "tests.test_optimize(optimize)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_nn(sess, epochs, batch_size, get_batches_fn, train_op, cross_entropy_loss, input_image,\n",
    "\n",
    "             correct_label, keep_prob, learning_rate):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Train neural network and print out the loss during training.\n",
    "\n",
    "    :param sess: TF Session\n",
    "\n",
    "    :param epochs: Number of epochs\n",
    "\n",
    "    :param batch_size: Batch size\n",
    "\n",
    "    :param get_batches_fn: Function to get batches of training data.  Call using get_batches_fn(batch_size)\n",
    "\n",
    "    :param train_op: TF Operation to train the neural network\n",
    "\n",
    "    :param cross_entropy_loss: TF Tensor for the amount of loss\n",
    "\n",
    "    :param input_image: TF Placeholder for input images\n",
    "\n",
    "    :param correct_label: TF Placeholder for label images\n",
    "\n",
    "    :param keep_prob: TF Placeholder for dropout keep probability\n",
    "\n",
    "    :param learning_rate: TF Placeholder for learning rate\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Implement function\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "\n",
    "    print('Starting training... for {} epochs'.format(epochs))\n",
    "\n",
    "    print()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        print('Epoch : {}'.format(epoch + 1))\n",
    "\n",
    "        loss_log = []\n",
    "\n",
    "        for image, label in get_batches_fn(batch_size):\n",
    "\n",
    "            _, loss = sess.run([train_op, cross_entropy_loss],\n",
    "\n",
    "                                feed_dict={\n",
    "\n",
    "                                    input_image: image,\n",
    "\n",
    "                                    correct_label: label,\n",
    "\n",
    "                                    keep_prob: 0.5,\n",
    "\n",
    "                                    learning_rate: 0.00001\n",
    "\n",
    "                                })\n",
    "\n",
    "            loss_log.append('{:3f}'.format(loss))\n",
    "\n",
    "        print(loss_log)\n",
    "\n",
    "        print()\n",
    "\n",
    "    print('Training finished')\n",
    "\n",
    "\n",
    "\n",
    "tests.test_train_nn(train_nn)\n",
    "\n",
    "\n",
    "\n",
    "def run():\n",
    "\n",
    "    num_classes = 2\n",
    "\n",
    "    image_shape = (160, 576)\n",
    "\n",
    "    data_dir = './data'\n",
    "\n",
    "    runs_dir = './runs'\n",
    "\n",
    "    model_dir = './models'\n",
    "\n",
    "    tests.test_for_kitti_dataset(data_dir)\n",
    "\n",
    "\n",
    "\n",
    "    # Download pretrained vgg model\n",
    "\n",
    "    helper.maybe_download_pretrained_vgg(data_dir)\n",
    "\n",
    "\n",
    "\n",
    "    # OPTIONAL: Train and Inference on the cityscapes dataset instead of the Kitti dataset.\n",
    "\n",
    "    # You'll need a GPU with at least 10 teraFLOPS to train on.\n",
    "\n",
    "    #  https://www.cityscapes-dataset.com/\n",
    "\n",
    "\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        # Path to vgg model\n",
    "\n",
    "        vgg_path = os.path.join(data_dir, 'vgg')\n",
    "\n",
    "        # Create function to get batches\n",
    "\n",
    "        get_batches_fn = helper.gen_batch_function(os.path.join(data_dir, 'data_road/training'), image_shape)\n",
    "\n",
    "\n",
    "\n",
    "        # OPTIONAL: Augment Images for better results\n",
    "\n",
    "        #  https://datascience.stackexchange.com/questions/5224/how-to-prepare-augment-images-for-neural-network\n",
    "\n",
    "\n",
    "\n",
    "        # TODO: Build NN using load_vgg, layers, and optimize function\n",
    "\n",
    "\n",
    "\n",
    "        # Placeholders\n",
    "\n",
    "        correct_label = tf.placeholder(tf.int32, [None, None, None, num_classes], name='correct_label')\n",
    "\n",
    "        learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n",
    "\n",
    "\n",
    "\n",
    "        # Getting layers from vgg.\n",
    "\n",
    "        input_image, keep_prob, layer3_out, layer4_out, layer7_out = load_vgg(sess, vgg_path)\n",
    "\n",
    "\n",
    "\n",
    "        # Creating new layers.\n",
    "\n",
    "        layer_output = layers(layer3_out, layer4_out, layer7_out, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "        # Creating loss and optimizer operations.\n",
    "\n",
    "        logits, train_op, cross_entropy_loss = optimize(layer_output, correct_label, learning_rate, num_classes)\n",
    "\n",
    "\n",
    "\n",
    "        # TODO: Train NN using the train_nn function\n",
    "\n",
    "        epochs = 48 # 6 12 24 \n",
    "\n",
    "        batch_size = 5\n",
    "\n",
    "\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "\n",
    "        train_nn(sess, epochs, batch_size, get_batches_fn, train_op, cross_entropy_loss, input_image,\n",
    "\n",
    "                 correct_label, keep_prob, learning_rate)\n",
    "\n",
    "\n",
    "\n",
    "        # TODO: Save inference data using helper.save_inference_samples\n",
    "\n",
    "        helper.save_inference_samples(model_dir, runs_dir, data_dir, sess, image_shape, logits, keep_prob, input_image, saver)\n",
    "\n",
    "\n",
    "\n",
    "        # OPTIONAL: Apply the trained model to a video\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
